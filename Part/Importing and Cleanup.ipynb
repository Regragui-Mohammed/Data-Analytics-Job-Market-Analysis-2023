{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb999a44",
   "metadata": {},
   "source": [
    "### ðŸ“Œ Libraries Used\n",
    "\n",
    "This project uses the following Python libraries:\n",
    "\n",
    "- **ast** â€” converts skills stored as strings into Python lists for analysis  \n",
    "- **pandas** â€” handles data cleaning, manipulation, and analysis  \n",
    "- **seaborn / matplotlib** â€” used to create visualizations and charts  \n",
    "- **datasets (HuggingFace)** â€” loads the dataset directly from HuggingFace using `load_dataset()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a631b66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "import ast\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6449ffae",
   "metadata": {},
   "source": [
    "## ðŸ“¥ Loading the Dataset\n",
    "\n",
    "In this step, I load the **data_jobs** dataset directly from HuggingFace using `load_dataset()`.  \n",
    "The dataset is then converted into a Pandas DataFrame to make it easier to clean, explore, and visualize throughout the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2593d363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "dataset = load_dataset('lukebarousse/data_jobs')\n",
    "df = dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a3de815",
   "metadata": {},
   "source": [
    "## ðŸ“Œ Dataset Inspection & Cleanup\n",
    "\n",
    "Before starting the analysis, I first inspect the dataset structure using `df.info()`.  \n",
    "This provides a quick overview of:\n",
    "\n",
    "- Total number of rows and columns  \n",
    "- Data types of each column  \n",
    "- Missing values across the dataset  \n",
    "\n",
    "After understanding the dataset format, I apply essential cleanup steps:\n",
    "\n",
    "1. **Convert `job_posted_date` to datetime format**  \n",
    "   This makes it possible to perform time-based analysis such as monthly or yearly trends.\n",
    "\n",
    "2. **Convert `job_skills` into Python list format**  \n",
    "   The skills column is stored as a string representation of a list, so I use `ast.literal_eval()` to transform it into real lists for accurate skill analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "652decff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 785741 entries, 0 to 785740\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   job_title_short        785741 non-null  object \n",
      " 1   job_title              785740 non-null  object \n",
      " 2   job_location           784696 non-null  object \n",
      " 3   job_via                785733 non-null  object \n",
      " 4   job_schedule_type      773074 non-null  object \n",
      " 5   job_work_from_home     785741 non-null  bool   \n",
      " 6   search_location        785741 non-null  object \n",
      " 7   job_posted_date        785741 non-null  object \n",
      " 8   job_no_degree_mention  785741 non-null  bool   \n",
      " 9   job_health_insurance   785741 non-null  bool   \n",
      " 10  job_country            785692 non-null  object \n",
      " 11  salary_rate            33067 non-null   object \n",
      " 12  salary_year_avg        22003 non-null   float64\n",
      " 13  salary_hour_avg        10662 non-null   float64\n",
      " 14  company_name           785723 non-null  object \n",
      " 15  job_skills             668704 non-null  object \n",
      " 16  job_type_skills        668704 non-null  object \n",
      "dtypes: bool(3), float64(2), object(12)\n",
      "memory usage: 86.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b28a5068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data cleanup\n",
    "df['job_posted_date'] = pd.to_datetime(df['job_posted_date'])\n",
    "df['job_skills'] = df['job_skills'].apply(lambda x : ast.literal_eval(x) if pd.notna(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03e58541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 785741 entries, 0 to 785740\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count   Dtype         \n",
      "---  ------                 --------------   -----         \n",
      " 0   job_title_short        785741 non-null  object        \n",
      " 1   job_title              785740 non-null  object        \n",
      " 2   job_location           784696 non-null  object        \n",
      " 3   job_via                785733 non-null  object        \n",
      " 4   job_schedule_type      773074 non-null  object        \n",
      " 5   job_work_from_home     785741 non-null  bool          \n",
      " 6   search_location        785741 non-null  object        \n",
      " 7   job_posted_date        785741 non-null  datetime64[ns]\n",
      " 8   job_no_degree_mention  785741 non-null  bool          \n",
      " 9   job_health_insurance   785741 non-null  bool          \n",
      " 10  job_country            785692 non-null  object        \n",
      " 11  salary_rate            33067 non-null   object        \n",
      " 12  salary_year_avg        22003 non-null   float64       \n",
      " 13  salary_hour_avg        10662 non-null   float64       \n",
      " 14  company_name           785723 non-null  object        \n",
      " 15  job_skills             668704 non-null  object        \n",
      " 16  job_type_skills        668704 non-null  object        \n",
      "dtypes: bool(3), datetime64[ns](1), float64(2), object(11)\n",
      "memory usage: 86.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
